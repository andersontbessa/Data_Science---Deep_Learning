{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questão 3 - Considerando o dataset diabetes.csv, o mesmo utilizado nas atividades das aulas de machine learning, faça o treinamento e avalie as métricas de teste, para os modelos Shallow e Deep vistos em aula. Compare os resultados considerando as métricas: Acurácia, Tempo de treino e tempo de teste em relação aos classificadores MLP, KNN e QDA (vistos na aula de machine learning). Crie uma tabela com as métricas e liste os resultados, comente brevemente os resultados apresentados. Considere a Tabela 1 1 para listar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten, Activation, Conv2D, MaxPool2D, Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import backend\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/lapisco/machine_learning_course.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFOLDER = path.join('..', '..', 'data')\n",
    "DATAFILES = ['diabetes.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(path.join(DATAFOLDER, DATAFILES[0]))\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.iloc[:, 0:8]\n",
    "y = diabetes.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "y = labelencoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallowModel = Sequential()\n",
    "shallowModel.add(Dense(1, input_shape=(8,), activation='sigmoid'))\n",
    "shallowModel.compile(Adam(lr=0.05), 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_time_train_start = time.time()\n",
    "shallowModel.fit(X_train, y_train, epochs=200, verbose=1)\n",
    "shallow_time_train_out = time.time()\n",
    "shallow_time_train_all = shallow_time_train_out - shallow_time_train_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_time_test_start = time.time()\n",
    "results=shallowModel.evaluate(X_test, y_test)\n",
    "shallow_time_test_out = time.time()\n",
    "shallow_time_test_all = shallow_time_test_out - shallow_time_test_start\n",
    "print('shallow_time_test_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_shallow = []\n",
    "metrics_shallow.extend((results[1],shallow_time_test_all,shallow_time_train_all))\n",
    "metrics_shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepModel = Sequential()\n",
    "deepModel.add(Dense(4, input_shape=(8,), activation='tanh')) \n",
    "deepModel.add(Dense(2, input_shape=(4,), activation='tanh'))\n",
    "deepModel.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n",
    "deepModel.compile(optimizer=Adam(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepModel_time_train_start = time.time()\n",
    "deepModel.fit(X_train, y_train, epochs=200, verbose=1)\n",
    "deepModel_time_train_Out = time.time()\n",
    "deepModel_time_train_all = deepModel_time_train_Out - deepModel_time_train_start\n",
    "print(deepModel_time_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepModel_time_test_start = time.time()\n",
    "deepResults = deepModel.evaluate(X_test, y_test)\n",
    "deepModel_time_test_out = time.time()\n",
    "deepModel_time_test_all = deepModel_time_test_out - deepModel_time_test_start\n",
    "print(deepModel_time_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deepResults[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_deep = []\n",
    "metrics_deep.extend((deepResults[1], deepModel_time_train_all, deepModel_time_test_all))\n",
    "metrics_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPclass = MLPClassifier(solver='adam', learning_rate='adaptive', hidden_layer_sizes = (100,), \n",
    "                        max_iter=1300, learning_rate_init=5e-04, tol=1e-4, random_state = 1)\n",
    "\n",
    "MLP_time_train_start = time.time()\n",
    "MLPclass.fit(X_train, y_train)\n",
    "MLP_time_train_out = time.time()\n",
    "MLP_time_train_all = MLP_time_train_out - MLP_time_train_start\n",
    "print(MLP_time_train_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_time_test_start = time.time()\n",
    "pred_y_mlp = MLPclass.predict(X_test)\n",
    "MLP_time_test_out = time.time()\n",
    "MLP_time_test_all = MLP_time_test_out - MLP_time_test_start\n",
    "print(MLP_time_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPL_acc_accuracy = accuracy_score(y_test, pred_y_mlp)\n",
    "print('Accuracy: ', MPL_acc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mlp = []\n",
    "metrics_mlp.extend((MPL_acc_accuracy, MLP_time_train_all, MLP_time_test_all))\n",
    "metrics_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\n",
    "knn_time_train_start = time.time()\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_time_train_out = time.time()\n",
    "knn_time_train_all = knn_time_train_out - knn_time_train_start\n",
    "print('knn training : ', knn_time_train_all)\n",
    "\n",
    "knn_time_test_start = time.time()\n",
    "pred_y_knn = KNN.predict(X_test)\n",
    "knn_time_test_out = time.time()\n",
    "knn_time_test_all = knn_time_test_out - knn_time_test_start\n",
    "print('knn test : ', knn_time_test_all)\n",
    "\n",
    "knn_acc_accuracy = accuracy_score(y_test, pred_y_knn)\n",
    "print('Train ACC KNN: ', knn_acc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_knn = []\n",
    "metrics_knn.extend((knn_acc_accuracy, knn_time_train_all, knn_time_test_all))\n",
    "metrics_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "\n",
    "qda_training_start = time.time()\n",
    "clf_qda.fit(X_train, y_train)\n",
    "qda_training_end = time.time()\n",
    "qda_training_total = qda_training_end - qda_training_start\n",
    "print('qda training : ', qda_training_total)\n",
    "\n",
    "qda_test_start = time.time()\n",
    "y_predicted_qda = clf_qda.predict(X_test)\n",
    "qda_test_end = time.time()\n",
    "qda_test_total = qda_test_end - qda_test_start\n",
    "print('qda test : ', qda_test_total)\n",
    "\n",
    "acc_qda = accuracy_score(y_test, y_predicted_qda)\n",
    "print('Train ACC QDA: ', acc_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_qda = []\n",
    "metrics_qda.extend((acc_qda, qda_training_total, qda_test_total))\n",
    "metrics_qda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import itertools\n",
    "#ListaMetrics_1 = list(itertools.chain(metrics_shallow,metrics_deep,metrics_mlp,metrics_knn, metrics_qda))\n",
    "#ListaMetrics_1\n",
    "\n",
    "ListaMetrics_1 = []\n",
    "ListaMetrics_1.append(metrics_shallow)\n",
    "ListaMetrics_1.append(metrics_deep)\n",
    "ListaMetrics_1.append(metrics_mlp)\n",
    "ListaMetrics_1.append(metrics_knn)\n",
    "ListaMetrics_1.append(metrics_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Acurácia', 'Tempo de treino', 'Tempo de teste']\n",
    "columns_id_q3 = ['Shallow', 'Deep', 'MLP', 'KNN', 'QDA']\n",
    "metrics_matrix_q3 = pd.DataFrame(data=ListaMetrics_1, columns=columns)\n",
    "metrics_matrix_q3.set_index(x for x in columns_id_q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questão 4 - Considerando o dataset MNIST (importe a partir do keras.datasets), dataset dos dígitos manuscritos utilizado nos exemplos de CNN em aula. Faça o treinamento e avalie as métricas de treino e teste, para os modelos Fully Connected Model e Convolutional Neural Network, vistos em aula e compare os resultados considerando as métricas: Acurácia, Tempo de treino e tempo de teste em relação aos classificadores MLP, KNN e QDA (para estes classificadores, lembre-se de utilizar a vetorização da imagem). Crie uma tabela com as métricas e liste os resultados, comente brevemente os resultados apresentados. Considere a Tabela 1 para listar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path='/tmp/mnist.npz')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[150], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)\n",
    "\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categ = to_categorical(y_train) \n",
    "y_test_categ = to_categorical(y_test)\n",
    "\n",
    "print(y_train[100])\n",
    "print(y_train_categ[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fully = Sequential()\n",
    "model_fully.add(Dense(512, input_dim=28*28, activation='relu'))\n",
    "model_fully.add(Dense(256, activation='relu'))\n",
    "model_fully.add(Dense(128, activation='relu'))\n",
    "model_fully.add(Dense(32, activation='relu'))\n",
    "model_fully.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_fully.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_time_train_start = time.time()\n",
    "fully_stor = model_fully.fit(X_train, y_train_categ, batch_size=128, epochs=10, verbose=1, validation_split=0.3)\n",
    "fully_time_train_out = time.time()\n",
    "fully_time_train_all = fully_time_train_out - fully_time_train_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_time_test_all = time.time()\n",
    "results_fully = model_fully.evaluate(X_test, y_test_categ)\n",
    "fully_time_test_out = time.time()\n",
    "fully_time_test_all = fully_time_test_out - fully_time_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_fully = []\n",
    "metrics_fully.extend((results_fully[1], fully_time_train_all, fully_time_test_all))\n",
    "metrics_fully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fully_stor.history['accuracy'])\n",
    "plt.plot(fully_stor.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path='/tmp/mnist.npz')\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()\n",
    "\n",
    "#AM: Feature extraction stages\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(64, (3,3), input_shape=(28, 28, 1), padding=('valid')))\n",
    "model_cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_cnn.add(Activation('relu'))\n",
    "\n",
    "model_cnn.add(Flatten())\n",
    "\n",
    "#AM: Fully connected stages (Classification)\n",
    "model_cnn.add(Dense(128, activation='relu'))\n",
    "model_cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_cnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_time_train_start = time.time()\n",
    "history_CNN = model_cnn.fit(X_train, y_train_categ, batch_size=128, epochs=10, verbose=1, validation_split=0.3)\n",
    "cnn_time_train_out = time.time()\n",
    "cnn_time_train_all = cnn_time_train_out - cnn_time_train_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_time_test_start = time.time()\n",
    "results_cnn = model_cnn.evaluate(X_test, y_test_categ)\n",
    "cnn_time_test_out = time.time()\n",
    "cnn_time_test_all = cnn_time_test_out - cnn_time_test_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_cnn = []\n",
    "metrics_cnn.extend((results_cnn[1], cnn_time_train_all, cnn_time_test_all))\n",
    "metrics_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_CNN.history['accuracy'])\n",
    "plt.plot(history_CNN.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import itertools\n",
    "#ListaMetrics_1 = list(itertools.chain(metrics_fully,metrics_cnn,metrics_mlp,metrics_knn, metrics_qda))\n",
    "#ListaMetrics_1\n",
    "\n",
    "ListaMetrics_4 = []\n",
    "\n",
    "ListaMetrics_4.append(metrics_fully)\n",
    "ListaMetrics_4.append(metrics_cnn)\n",
    "ListaMetrics_4.append(metrics_mlp)\n",
    "ListaMetrics_4.append(metrics_knn)\n",
    "ListaMetrics_4.append(metrics_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Acurácia', 'Tempo de treino', 'Tempo de teste']\n",
    "columns_id_q4 = ['Fully', 'CNN', 'MLP', 'KNN', 'QDA']\n",
    "metrics_matrix_q4 = pd.DataFrame(data=data_q4, columns=columns)\n",
    "metrics_matrix_q4.set_index(x for x in columns_id_q4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python data science",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
